---
title: "Analyzing a billion NYC taxi trips in Spark"
output: html_notebook
---

# Overview

We analyze the full taxi data as described by [Todd Schneider](http://toddwschneider.com/posts/analyzing-1-1-billion-nyc-taxi-and-uber-trips-with-a-vengeance/) in using R and sparklyr. We load the billion record trips table into Apache Spark and then use sparklyr and dplyr to manipulate the data and run machine learning algorithms at scale.

# Connect

The data represent 200 GB of uncompressed data in CSV format. When converted and compressed in the parquet format, the data are 70 GB. The data are stored in HDFS and pre-loaded in a Hive table.

The Hadoop cluster runs on Elastic Map Reduce (EMR) in AWS and has 12 worker nodes and one master node. The master node has R, RStudio Server Pro, and sparklyr loaded onto it.

Use sparklyr to create a new connection to Apache Spark and cache the trips table. 

```{r connect}
library(ggplot2)
library(leaflet)
library(geosphere)
library(tidyr)
library(shiny)
library(sparklyr)
library(dplyr)

Sys.setenv(SPARK_HOME="/usr/lib/spark")
config <- spark_config()
sc <- spark_connect(master = "yarn-client", config = config, version = '1.6.1')

tbl_cache(sc, 'trips_par') # 9.6 minute
trips_tbl <- tbl(sc, 'trips_par')
```

# Number of trips

Use dplyr syntax to write Spark SQL. When you're ready to visualize your data, use `collect` to bring data into R memory. Notice the data describe roughly 170 million trips per year.

```{r}
trips_tbl %>% count

trip_by_year <- trips_tbl %>%
  mutate(year = year(pickup_datetime)) %>%
  group_by(year) %>%
  summarize(n = n()) %>%
  collect()

ggplot(trip_by_year, aes(year, n)) + 
  geom_bar(stat="Identity") +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Number of trips by year", x = "Year", y = "")
```

# Top dropoffs

Spark makes it easy to drill down to any level of you data. You can visualize the top dropoffs for any pickup location by entering your pickup location. In this example the pickup location is JFK International Airport.

```{r}
jfk_pickup_tbl <- trips_tbl %>%
  filter(pickup_nyct2010_gid == 2056) %>%
  filter(!is.na(dropoff_nyct2010_gid)) %>%
  mutate(trip_time = unix_timestamp(dropoff_datetime) - unix_timestamp(pickup_datetime)) %>%
  group_by(dropoff_nyct2010_gid) %>% 
  summarize(n = n(),
            trip_time_mean = mean(trip_time),
            trip_dist_mean = mean(trip_distance),
            dropoff_latitude = mean(dropoff_latitude),
            dropoff_longitude = mean(dropoff_longitude),
            passenger_mean = mean(passenger_count),
            fare_amount = mean(fare_amount),
            tip_amount = mean(tip_amount))

jfk_pickup <- jfk_pickup_tbl %>%
  mutate(n_rank = min_rank(desc(n))) %>%
  filter(n_rank <= 25) %>%
  collect

leaflet(jfk_pickup) %>% 
  setView(lng = -73.9, lat = 40.7, zoom = 11) %>%
  addProviderTiles("CartoDB.Positron") %>%
  addCircleMarkers(~dropoff_longitude, ~dropoff_latitude, stroke = F) %>%
  addCircleMarkers(-73.7781, 40.6413)
```


### Trip duration

You can measure the time between pickup and dropoff for any two locations. In this example, we measure the time between JFK and mid-town. Notice the longest trip times occur around 4 PM.

```{r}
pickup_dropoff_tbl <- trips_tbl %>%
  filter(pickup_nyct2010_gid == 1250 & dropoff_nyct2010_gid == 2056) %>%
  mutate(pickup_hour = hour(pickup_datetime)) %>%
  mutate(trip_time = unix_timestamp(dropoff_datetime) - unix_timestamp(pickup_datetime)) %>%
  group_by(pickup_hour) %>% 
  summarize(n = n(),
            trip_time_mean = mean(trip_time),
            trip_time_p10 = percentile(trip_time, 0.10),
            trip_time_p25 = percentile(trip_time, 0.25),
            trip_time_p50 = percentile(trip_time, 0.50),
            trip_time_p75 = percentile(trip_time, 0.75),
            trip_time_p90 = percentile(trip_time, 0.90))

pickup_dropoff <- collect(pickup_dropoff_tbl)

ggplot(pickup_dropoff, aes(x = pickup_hour)) +
          geom_line(aes(y = trip_time_p50, alpha = "Median")) +
          geom_ribbon(aes(ymin = trip_time_p25, ymax = trip_time_p75, alpha = "25–75th percentile")) +
          geom_ribbon(aes(ymin = trip_time_p10, ymax = trip_time_p90, alpha = "10–90th percentile")) +
          scale_y_continuous("trip duration in minutes")

```

# Predict tip amount

With Spark ML you can run machine learning algorithms against all your data in Spark. Here we attempt to understand what factors influence tip amounts.

```{r}
model_tbl <- trips_tbl %>%
  filter(pickup_nyct2010_gid == 1250 & dropoff_nyct2010_gid == 2056) %>%
  mutate(pickup_hour = hour(pickup_datetime)) %>%
  mutate(pickup_week = weekofyear(pickup_datetime)) %>%
  mutate(pickup_year = year(pickup_datetime)) %>%
  mutate(trip_time = unix_timestamp(dropoff_datetime) - unix_timestamp(pickup_datetime)) %>%
  filter(!is.na(pickup_nyct2010_gid) & !is.na(dropoff_nyct2010_gid)) %>%
  filter(!is.na(tip_amount)) %>%
  filter(!is.na(fare_amount)) %>%
  filter(!is.na(vendor_id)) %>%
  filter(!is.na(pickup_hour)) %>%
  filter(!is.na(pickup_week)) %>%
  filter(!is.na(passenger_count)) %>%
  filter(!is.na(trip_time)) %>%
  filter(!is.na(trip_distance))

model_partition_tbl <- model_tbl %>%
  sdf_partition(train = 0.8, test = 0.2, seed = 1234)

trips_train_tbl <- sdf_register(model_partition_tbl$train, "trips_train")
trips_test_tbl <- sdf_register(model_partition_tbl$train, "trips_test")

tbl_cache(sc, "trips_train")
tbl_cache(sc, "trips_test")

model_formula <- formula(tip_amount ~ 
                           fare_amount + vendor_id + pickup_hour + pickup_week + 
                           passenger_count + trip_time + trip_distance)

m1 <- ml_linear_regression(trips_train_tbl, model_formula)
summary(m1)

trips_score_tbl <- sdf_predict(m1, trips_test_tbl)
```

# Visualize trip duration with Shiny

It is often useful to visualize the analyses interactively. Use the Shiny app to explore other pickup and dropoff locations.

First, create a few objects in the global evironment that will be required by Shiny.

```{r}

shiny_sc <<- sc
shiny_trips_tbl <<- tbl(sc, 'trips_par')
  
distinct_gid <- function(data, gid, cutoff = 100000){
  data %>%
    group_by_(gid) %>%
    count %>%
    filter(n > cutoff) %>%
    select_(gid) %>%
    arrange_(gid) %>%
    collect
}

pickup_nyct2010_gid <<- shiny_trips_tbl %>%
  distinct_gid("pickup_nyct2010_gid") %>%
  unlist %>%
  unname %>%
  na.omit

dropoff_nyct2010_gid <<- shiny_trips_tbl %>%
  distinct_gid("dropoff_nyct2010_gid") %>%
  unlist %>%
  unname %>%
  na.omit

```

Next, create a Shiny app.

```{r}

ui <- fluidPage(
   
   titlePanel("NYC Taxi Trips"),
   
   sidebarLayout(
      sidebarPanel(
        selectInput("pickup",  "Taxi origin", pickup_nyct2010_gid, 1250),
        selectInput("dropoff",  "Taxi destination", dropoff_nyct2010_gid, 2056)
      ),
      
      mainPanel(
         plotOutput("distPlot")
      )
   )
)

server <- function(input, output) {

  shiny_pickup_dropoff <- reactive({
    shiny_trips_tbl %>%
    #filter(pickup_nyct2010_gid == 1250 & dropoff_nyct2010_gid == 2056) %>%
    filter(pickup_nyct2010_gid == input$pickup & dropoff_nyct2010_gid == input$dropoff) %>%
    mutate(pickup_hour = hour(pickup_datetime)) %>%
    mutate(trip_time = unix_timestamp(dropoff_datetime) - unix_timestamp(pickup_datetime)) %>%
    group_by(pickup_hour) %>% 
    summarize(n = n(),
              trip_time_p10 = percentile(trip_time, 0.10),
              trip_time_p25 = percentile(trip_time, 0.25),
              trip_time_p50 = percentile(trip_time, 0.50),
              trip_time_p75 = percentile(trip_time, 0.75),
              trip_time_p90 = percentile(trip_time, 0.90)) %>%
    collect
  })
  
  output$distPlot <- renderPlot({
    ggplot(shiny_pickup_dropoff(), aes(x = pickup_hour)) +
    geom_line(aes(y = trip_time_p50, alpha = "Median")) +
    geom_ribbon(aes(ymin = trip_time_p25, ymax = trip_time_p75, alpha = "25–75th percentile")) +
    geom_ribbon(aes(ymin = trip_time_p10, ymax = trip_time_p90, alpha = "10–90th percentile")) +
    scale_y_continuous("trip duration in minutes") +
    ggtitle(paste("Pickup = ", input$pickup, ";", "Dropoff =", input$dropoff))
   })
  
}

shinyApp(ui = ui, server = server)
```


